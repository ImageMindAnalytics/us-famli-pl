{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccba0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/mnt/raid/C1_ML_Analysis/source/us-famli-pl/src/\")\n",
    "from nets.classification import RopeEffnetV2s\n",
    "from loaders.ultrasound_dataset import USAnnotatedBlindSweepDataModule\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def _frame_to_png_bytes(frame2d: np.ndarray) -> bytes:\n",
    "    \"\"\"Convert a (C,H,W) frame (any numeric dtype) to PNG bytes for ipywidgets.Image.\"\"\"\n",
    "    f = np.asarray(frame2d)\n",
    "    # Handle NaNs/infs safely\n",
    "    f = np.nan_to_num(f, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Normalize to uint8\n",
    "    fmin = float(f.min())\n",
    "    fmax = float(f.max())\n",
    "    if fmax > fmin:\n",
    "        u8 = ((f - fmin) / (fmax - fmin) * 255.0).astype(np.uint8)\n",
    "    else:\n",
    "        u8 = np.zeros_like(f, dtype=np.uint8)\n",
    "\n",
    "    img = Image.fromarray(u8, mode=\"RGB\")  # RGB\n",
    "    buf = io.BytesIO()\n",
    "    img.save(buf, format=\"PNG\")\n",
    "    return buf.getvalue()\n",
    "\n",
    "\n",
    "def visualize_sequence(\n",
    "    images: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    scores_pred: np.ndarray,\n",
    "    *,\n",
    "    fps: float = 10.0,\n",
    "    title: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Jupyter-stable interactive viewer:\n",
    "      - Left: grayscale frame shown via ipywidgets.Image\n",
    "      - Right: Plotly line plots for GT + Pred with moving markers + vertical line\n",
    "      - Controls: Play + Slider\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images : np.ndarray\n",
    "        Shape (T,H,W) or (C,T,H,W) or (T,H,W,C) supported if you tweak below.\n",
    "        (Your code uses a helper _frame_to_png_bytes(frame) that expects a single frame.)\n",
    "    scores : array-like\n",
    "        Shape (T,), GT score per frame.\n",
    "    scores_pred : array-like\n",
    "        Shape (T,), predicted score per frame.\n",
    "    \"\"\"\n",
    "    images = np.asarray(images)\n",
    "    if images.ndim != 4:\n",
    "        raise ValueError(f\"`images` must have shape (T,H,W,C) (per your current code). Got {images.shape}\")\n",
    "\n",
    "    # Your original code says (C,T,H,W) but then unpacks as (T,H,W,C).\n",
    "    # Keeping your current behavior: images.shape == (T,H,W,C)\n",
    "    T, H, W, C = images.shape\n",
    "\n",
    "    scores_np = np.asarray(scores).reshape(-1)\n",
    "    if scores_np.shape[0] != T:\n",
    "        raise ValueError(f\"`scores` length must match T={T}. Got {scores_np.shape[0]}\")\n",
    "\n",
    "    scores_pred_np = np.asarray(scores_pred).reshape(-1)\n",
    "    if scores_pred_np.shape[0] != T:\n",
    "        raise ValueError(f\"`scores_pred` length must match T={T}. Got {scores_pred_np.shape[0]}\")\n",
    "\n",
    "    # --- Widgets ---\n",
    "    slider = widgets.IntSlider(value=0, min=0, max=T - 1, step=1, description=\"Frame\", continuous_update=True)\n",
    "    play = widgets.Play(\n",
    "        value=0, min=0, max=T - 1, step=1,\n",
    "        interval=int(1000 / max(fps, 1e-6)),\n",
    "        description=\"Play\",\n",
    "    )\n",
    "    widgets.jslink((play, \"value\"), (slider, \"value\"))\n",
    "\n",
    "    # Image display (PNG bytes)\n",
    "    img_w = widgets.Image(value=_frame_to_png_bytes(images[0]), format=\"png\")\n",
    "\n",
    "    # Metadata panel\n",
    "    meta = widgets.HTML()\n",
    "    def _meta_html(i: int) -> str:\n",
    "        base = (\n",
    "            f\"<b>frame:</b> {i}\"\n",
    "            f\"<br><b>score (gt):</b> {scores_np[i]:.3f}\"\n",
    "            f\"<br><b>score (pred):</b> {scores_pred_np[i]:.3f}\"\n",
    "        )\n",
    "        return base\n",
    "\n",
    "    meta.value = _meta_html(0)\n",
    "\n",
    "    # Plotly FigureWidget\n",
    "    x = np.arange(T)\n",
    "    fig = go.FigureWidget()\n",
    "\n",
    "    # Lines\n",
    "    fig.add_scatter(x=x, y=scores_np,      mode=\"lines\", name=\"score (gt)\")\n",
    "    fig.add_scatter(x=x, y=scores_pred_np, mode=\"lines\", name=\"score (pred)\")\n",
    "\n",
    "    # Current markers (one for each series)\n",
    "    fig.add_scatter(x=[0], y=[float(scores_np[0])],      mode=\"markers\", name=\"current (gt)\")\n",
    "    fig.add_scatter(x=[0], y=[float(scores_pred_np[0])], mode=\"markers\", name=\"current (pred)\")\n",
    "\n",
    "    # Add max predicted score line\n",
    "    max_pred_idx = int(np.argmax(scores_pred_np))\n",
    "    fig.add_scatter(\n",
    "        x=[max_pred_idx],\n",
    "        y=[float(scores_pred_np[max_pred_idx])],\n",
    "        mode=\"markers\",\n",
    "        name=\"max score (pred)\",\n",
    "        marker=dict(color=\"green\", size=10, symbol=\"x\"),\n",
    "    )\n",
    "\n",
    "    # y-range for the vertical line: cover both series\n",
    "    y_min = float(np.min([scores_np.min(), scores_pred_np.min()]))\n",
    "    y_max = float(np.max([scores_np.max(), scores_pred_np.max()]))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Frame\",\n",
    "        yaxis_title=\"Score\",\n",
    "        margin=dict(l=40, r=10, t=40, b=40),\n",
    "        shapes=[\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                x0=0, x1=0,\n",
    "                y0=y_min, y1=y_max,\n",
    "                xref=\"x\", yref=\"y\",\n",
    "                line=dict(width=2, dash=\"dash\"),\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    def _update(i: int):\n",
    "        # Update image\n",
    "        img_w.value = _frame_to_png_bytes(images[i])\n",
    "\n",
    "        # Update markers + vertical line\n",
    "        with fig.batch_update():\n",
    "            # marker traces are indices 2 and 3\n",
    "            fig.data[2].x = (i,)\n",
    "            fig.data[2].y = (float(scores_np[i]),)\n",
    "\n",
    "            fig.data[3].x = (i,)\n",
    "            fig.data[3].y = (float(scores_pred_np[i]),)\n",
    "\n",
    "            # keep line spanning both series ranges (or recompute if you want dynamic)\n",
    "            fig.layout.shapes[0].update(x0=i, x1=i, y0=y_min, y1=y_max)\n",
    "\n",
    "        # Update metadata\n",
    "        meta.value = _meta_html(i)\n",
    "\n",
    "    slider.observe(lambda ch: _update(ch[\"new\"]), names=\"value\")\n",
    "\n",
    "    controls = widgets.HBox([play, slider])\n",
    "    left = widgets.VBox([meta, img_w])\n",
    "    right = widgets.VBox([fig])\n",
    "    ui = widgets.VBox([controls, widgets.HBox([left, right])])\n",
    "\n",
    "    return ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _to_uint8_rgb_per_frame(frame: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a single frame (H,W) or (H,W,C) to uint8 RGB using per-frame min/max,\n",
    "    matching the spirit of your widget normalization.\n",
    "    \"\"\"\n",
    "    f = np.asarray(frame)\n",
    "    f = np.nan_to_num(f, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    if f.ndim == 2:\n",
    "        f = f[..., None]  # (H,W,1)\n",
    "    if f.shape[-1] == 1:\n",
    "        f = np.repeat(f, 3, axis=-1)\n",
    "    elif f.shape[-1] != 3:\n",
    "        raise ValueError(f\"Expected 1 or 3 channels, got {f.shape[-1]}\")\n",
    "\n",
    "    fmin = float(f.min())\n",
    "    fmax = float(f.max())\n",
    "    if fmax > fmin:\n",
    "        u8 = ((f - fmin) / (fmax - fmin) * 255.0).astype(np.uint8)\n",
    "    else:\n",
    "        u8 = np.zeros_like(f, dtype=np.uint8)\n",
    "\n",
    "    return u8  # (H,W,3) uint8\n",
    "\n",
    "\n",
    "def export_widget_like_mp4(\n",
    "    images: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    scores_pred: np.ndarray,\n",
    "    out_mp4: str,\n",
    "    *,\n",
    "    fps: float = 10.0,\n",
    "    title: str = \"Sequence\",\n",
    "    show_filename: bool = False,\n",
    "    filenames=None,\n",
    "    dpi: int = 120,\n",
    "):\n",
    "    \"\"\"\n",
    "    Export a widget-like video:\n",
    "      left: image + text metadata\n",
    "      right: plot (gt + pred) + current markers + vertical line + max pred marker\n",
    "\n",
    "    images: (T,H,W,C) or (T,H,W) or (T,H,W,1) or (T,H,W,3)\n",
    "    scores, scores_pred: (T,)\n",
    "    filenames: optional (T,)\n",
    "    \"\"\"\n",
    "    imgs = np.asarray(images)\n",
    "    if imgs.ndim == 3:  # (T,H,W)\n",
    "        imgs = imgs[..., None]\n",
    "    if imgs.ndim != 4:\n",
    "        raise ValueError(f\"images must be (T,H,W) or (T,H,W,C). Got {imgs.shape}\")\n",
    "\n",
    "    T, H, W, C = imgs.shape\n",
    "    scores = np.asarray(scores).reshape(-1)\n",
    "    scores_pred = np.asarray(scores_pred).reshape(-1)\n",
    "    if scores.shape[0] != T or scores_pred.shape[0] != T:\n",
    "        raise ValueError(f\"scores and scores_pred must have length T={T}. Got {scores.shape[0]} and {scores_pred.shape[0]}\")\n",
    "\n",
    "    if show_filename:\n",
    "        if filenames is None:\n",
    "            raise ValueError(\"show_filename=True requires filenames=\")\n",
    "        filenames = np.asarray(filenames).reshape(-1)\n",
    "        if filenames.shape[0] != T:\n",
    "            raise ValueError(f\"filenames must have length T={T}. Got {filenames.shape[0]}\")\n",
    "\n",
    "    x = np.arange(T)\n",
    "    y_min = float(np.min([scores.min(), scores_pred.min()]))\n",
    "    y_max = float(np.max([scores.max(), scores_pred.max()]))\n",
    "    max_pred_idx = int(np.argmax(scores_pred))\n",
    "\n",
    "    # Video writer settings\n",
    "    # Note: imageio uses ffmpeg; install imageio-ffmpeg if needed.\n",
    "    frames = []\n",
    "\n",
    "    # Create one figure and update it per frame (faster than recreating).\n",
    "    fig = plt.figure(figsize=(12, 5), dpi=dpi)\n",
    "    gs = fig.add_gridspec(1, 2, width_ratios=[1.0, 1.6])\n",
    "\n",
    "    ax_img = fig.add_subplot(gs[0, 0])\n",
    "    ax_plot = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "    # --- Initialize left panel ---\n",
    "    ax_img.axis(\"off\")\n",
    "    im_artist = ax_img.imshow(_to_uint8_rgb_per_frame(imgs[0]), interpolation=\"nearest\")\n",
    "    meta_text = ax_img.text(\n",
    "        0.02, 0.98, \"\",\n",
    "        transform=ax_img.transAxes,\n",
    "        va=\"top\", ha=\"left\",\n",
    "        fontsize=10,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", alpha=0.8)\n",
    "    )\n",
    "\n",
    "    # --- Initialize right panel plot ---\n",
    "    ax_plot.set_title(title)\n",
    "    ax_plot.set_xlabel(\"Frame\")\n",
    "    ax_plot.set_ylabel(\"Score\")\n",
    "    ax_plot.set_xlim(0, T - 1)\n",
    "    ax_plot.set_ylim(y_min, y_max)\n",
    "\n",
    "    (line_gt,) = ax_plot.plot(x, scores, label=\"score (gt)\")\n",
    "    (line_pred,) = ax_plot.plot(x, scores_pred, label=\"score (pred)\")\n",
    "\n",
    "    # current markers\n",
    "    (cur_gt,) = ax_plot.plot([0], [float(scores[0])], marker=\"o\", linestyle=\"None\", label=\"current (gt)\")\n",
    "    (cur_pred,) = ax_plot.plot([0], [float(scores_pred[0])], marker=\"o\", linestyle=\"None\", label=\"current (pred)\")\n",
    "\n",
    "    # max pred marker\n",
    "    ax_plot.plot([max_pred_idx], [float(scores_pred[max_pred_idx])], marker=\"x\", linestyle=\"None\", markersize=10, label=\"max score (pred)\")\n",
    "\n",
    "    # vertical line\n",
    "    vline = ax_plot.axvline(0, linestyle=\"--\")\n",
    "\n",
    "    ax_plot.legend(loc=\"best\")\n",
    "\n",
    "    def _meta(i: int) -> str:\n",
    "        s = f\"frame: {i}\\nscore (gt): {scores[i]:.3f}\\nscore (pred): {scores_pred[i]:.3f}\"\n",
    "        if show_filename:\n",
    "            s += f\"\\nfile: {filenames[i]}\"\n",
    "        return s\n",
    "\n",
    "    meta_text.set_text(_meta(0))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Render loop\n",
    "    for i in range(T):\n",
    "        im_artist.set_data(_to_uint8_rgb_per_frame(imgs[i]))\n",
    "        meta_text.set_text(_meta(i))\n",
    "\n",
    "        cur_gt.set_data([i], [float(scores[i])])\n",
    "        cur_pred.set_data([i], [float(scores_pred[i])])\n",
    "        vline.set_xdata([i, i])\n",
    "\n",
    "        # draw -> RGB array\n",
    "        fig.canvas.draw()\n",
    "        w, h = fig.canvas.get_width_height()\n",
    "        buf = np.asarray(fig.canvas.buffer_rgba())\n",
    "        rgb = buf[..., :3].copy()  # drop alpha channel\n",
    "        frames.append(rgb)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    frames_np = np.stack(frames, axis=0)  # (T,H,W,3)\n",
    "    iio.imwrite(out_mp4, frames_np, fps=fps, codec=\"libx264\", pixelformat=\"yuv420p\")\n",
    "    return out_mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b04996",
   "metadata": {},
   "outputs": [],
   "source": [
    "mount_point = '/mnt/raid/C1_ML_Analysis'\n",
    "\n",
    "dev_id = 0\n",
    "device = torch.device(f'cuda:{dev_id}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v1.5/epoch=40-val_select=0.844.ckpt') # sigma 0.18, 0.12, 0.12, 0.1, 0.07)\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v1.5/epoch=48-val_select=0.805.ckpt')\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v1.6/epoch=39-val_select=0.770.ckpt')  # sigma -> 0.18, 0.12, 0.12, 0.1, 0.06\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v1.7/epoch=14-val_select=0.788.ckpt')\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v0.17/epoch=38-val_select=0.722.ckpt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v0.15/epoch=27-val_select=0.699.ckpt')\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v0.16/epoch=39-val_select=0.576.ckpt')\n",
    "\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v0.18/epoch=40-val_select=0.538.ckpt') # sigma -> Good 0.16 0.12 0.12 0.1 0.06\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v0.19/epoch=43-val_select=0.538.ckpt') # 0.14, 0.12, 0.12, 0.1, 0.08\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v1.8/epoch=44-val_select=0.769.ckpt') # Best one -> 0.14, 0.12, 0.12, 0.08, 0.04]\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v2.1/epoch=46-val_select=0.825.ckpt') # 0.14, 0.12, 0.1, 0.08, 0.04\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v2.2/epoch=27-val_select=0.774.ckpt') # 0.14, 0.12, 0.1, 0.08, 0.04 \"reject_tau\"  0.85\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v2.4/epoch=50-val_select=0.803.ckpt') # 0.14, 0.12, 0.1, 0.08, 0.04 temporal_score_tv_weight 0.1\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v2.5/epoch=62-val_select=0.744.ckpt') # 0.14, 0.12, 0.1, 0.08, 0.04 temporal_score_tv_weight 0.2\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v2.8/epoch=18-val_select=0.416.ckpt') \n",
    "\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v3.0/epoch=24-val_select=0.704.ckpt') \n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v3.4/epoch=19-val_select=0.825.ckpt')\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v4.1/epoch=36-val_select=0.856.ckpt')\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v5.0/epoch=16-val_select=0.802.ckpt') # 0.08, 0.12, 0.12, 0.09, 0.04\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v7.5/epoch=48-val_select=0.768.ckpt') # 0.09, 0.12, 0.12, 0.11, 0.06\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v7.6/epoch=32-val_select=0.760.ckpt') # 0.12 0.12 0.12 0.12 0.12\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v8.1/epoch=26-val_select=0.826.ckpt') # 0.09, 0.1, 0.1, 0.09, 0.08 top_aux [500, 2000] 0.1\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v8.2/epoch=41-val_select=0.738.ckpt') # 0.09, 0.12, 0.12, 0.1, 0.08 top_aux [500, 2000] 0.1\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v8.3/epoch=21-val_select=0.807.ckpt') # 0.14, 0.12, 0.12, 0.08, 0.04 top_aux 0, 2000 0.05\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v8.4/last.ckpt') # 0.14, 0.12, 0.12, 0.08, 0.04 top_aux [0, 2000] 0.1\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v8.6/epoch=22-val_select=0.705.ckpt') # 0.14, 0.12, 0.12, 0.08, 0.04 top_aux [0, 2000] 0.1\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v9.0/epoch=21-val_select=0.852.ckpt') # 0.14, 0.12, 0.1, 0.08, 0.04 top_aux [0, 2000] 0.1\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v9.1/epoch=40-val_select=0.692.ckpt')  # 0.08 0.08 0.08 0.08 0.06\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v9.2/epoch=19-val_select=0.817.ckpt') # 0.08, 0.16, 0.12, 0.08, 0.04 top_aux [0, 2000] 0.1\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v9.3/epoch=20-val_select=0.743.ckpt') # 0.14, 0.12, 0.1, 0.08, 0.06 top_aux 0.05 [2000, 4000\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v9.8/epoch=16-val_rec_top3=0.363.ckpt') # 0.16, 0.12, 0.12, 0.08, 0.04 \n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v9.9/epoch=33-val_rec_top3=0.405.ckpt') # 0.1, 0.16, 0.12, 0.08, 0.04\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v10.0/epoch=38-val_select=0.398.ckpt') # 0.1, 0.12, 0.12, 0.08, 0.04 top_aux 0 -> Very Good!\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v10.1/epoch=58-val_select=0.396.ckpt') # 0.14, 0.12, 0.1, 0.08, 0.06 top_aux 0\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/v10.3/epoch=52-val_rec_top3=0.371.ckpt') # 0.08, 0.12, 0.12, 0.08, 0.04 top_aux 0\n",
    "# model_fn = os.path.join(mount_point, 'train_output/classification/RopeEffnet/', 'v10.4/epoch=60-val_select=0.383.ckpt') # 0.1, 0.12, 0.1, 0.08, 0.04]\n",
    "\n",
    "model = RopeEffnetV2s.load_from_checkpoint(model_fn, map_location=device).eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a48083",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = USAnnotatedBlindSweepDataModule(**model.hparams)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53916675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(dm, model):\n",
    "    \n",
    "    output_csv = model_fn.replace('.ckpt', '_predictions.csv')\n",
    "\n",
    "    if os.path.exists(output_csv):\n",
    "        print(f\"Predictions file {output_csv} already exists. Loading it.\")\n",
    "        df = pd.read_csv(output_csv)\n",
    "        return df\n",
    "    \n",
    "    test_dl = dm.test_dataloader()\n",
    "    test_ds = dm.test_ds\n",
    "\n",
    "    df_scores = []\n",
    "    with torch.no_grad():\n",
    "        for idx, X_d in tqdm(enumerate(test_dl), total=len(test_dl)):\n",
    "            file_path = test_ds.df.iloc[idx]['file_path']\n",
    "            logits = model(X_d['img'].permute(0, 2, 1, 3, 4).to(device))  # [B, N, C]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            levels = torch.tensor([0.0, 0.25, 0.5, 0.75, 1.0], device=probs.device)\n",
    "            score = (probs * levels).sum(dim=-1)  # [B, N]\n",
    "\n",
    "            df = pd.DataFrame({\n",
    "                'frame_index': list(np.arange(X_d['img'].shape[2])),\n",
    "                'file_path': file_path,\n",
    "                'score_pred': score.squeeze().cpu().numpy(),\n",
    "                'score': X_d['scalar'].squeeze().cpu().numpy(),\n",
    "            })\n",
    "            df_scores.append(df)    \n",
    "    df = pd.concat(df_scores, ignore_index=True)\n",
    "\n",
    "    if not os.path.basename(model_fn) == \"last.ckpt\":\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"Saved predictions to {output_csv}\")\n",
    "    return df\n",
    "\n",
    "df_test_pred = run_test(dm, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b251014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred['error'] = df_test_pred['score_pred'] - df_test_pred['score']\n",
    "df_test_pred['abs_error'] = df_test_pred['error'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd58268",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred['abs_error'].describe(percentiles=[0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "def to_class(x):\n",
    "    return np.argmin(np.abs(bins - x))\n",
    "\n",
    "df_test_pred[\"y_true\"] = df_test_pred.score.apply(to_class)\n",
    "df_test_pred[\"y_pred\"] = df_test_pred.score_pred.apply(to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77868242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "cm = confusion_matrix(df_test_pred['y_true'], df_test_pred['y_pred'])\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(bins))\n",
    "\n",
    "fmt = '.3f' \n",
    "thresh = cm_norm.max() / 2.\n",
    "for i, j in itertools.product(range(cm_norm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm_norm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xticks(tick_marks, [f\"{b:.2f}\" for b in bins])\n",
    "plt.yticks(tick_marks, [f\"{b:.2f}\" for b in bins])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(df_test_pred['y_true'], df_test_pred['y_pred'], target_names=['0.0', '0.25', '0.5', '0.75', '1.0'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09366e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df_test_pred.score == 1.0\n",
    "plt.hist(df_test_pred.score_pred[m], bins=30)\n",
    "plt.axvline(1.0, color=\"r\")\n",
    "plt.title(\"Predictions for true high_measurable (1.0)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [0.7, 0.8, 0.9]:\n",
    "    tp = np.mean(df_test_pred.score_pred[df_test_pred.score == 1.0] >= t)\n",
    "    print(f\"P(score_pred >= {t} | true=1.0) = {tp:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd15ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [0.5, 0.9]:\n",
    "    tp = np.mean(df_test_pred.score_pred[df_test_pred.score == 0.0] >= t)\n",
    "    print(f\"P(score_pred >= {t} | true=0.0) = {tp:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace14510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = (\n",
    "    df_test_pred.groupby(\"file_path\")\n",
    "      .agg(score_max=(\"score\",\"max\"), pred_max=(\"score_pred\",\"max\"))\n",
    "      .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(df_seq, y=\"pred_max\", x=\"score_max\", box=True, points=\"all\", title=f\"Predicted max score vs GT max score per sequence - sigma {model.hparams.sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(df_test_pred, y=\"score_pred\", x=\"score\", box=True, points=\"outliers\", title=f\"Predicted score vs GT score per frame - sigma {model.hparams.sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in [0, 0.25, 0.5, 0.75, 1.0]:\n",
    "    print(f\"Score: {s}\")\n",
    "    print(df_test_pred.query(f'score == {s}')['score_pred'].describe(percentiles=[.01, .1, .25, 0.5, 0.75, 0.9, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b88420",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = dm.test_ds\n",
    "df_frames = test_ds.df_frames\n",
    "df = test_ds.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ce87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_seq.query('score_max >= 0.75 and pred_max <= 0.25')['file_path'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f015f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = df_test_pred.query('score_pred >= 0.45 and score == 0.0')['file_path'].drop_duplicates()\n",
    "print(len(file_paths))\n",
    "idx = 36\n",
    "file_path = file_paths.iloc[idx]\n",
    "\n",
    "print(file_path)\n",
    "q = df_test_pred.query('file_path == @file_path')\n",
    "score, score_pred = q['score'], q['score_pred']\n",
    "\n",
    "img = sitk.ReadImage(os.path.join(mount_point, file_path))\n",
    "img_np = sitk.GetArrayFromImage(img)  # [T,H,W]\n",
    "\n",
    "if img.GetNumberOfComponentsPerPixel() == 1:\n",
    "    img_np = np.expand_dims(img_np, -1).repeat(3, axis=-1)\n",
    "\n",
    "visualize_sequence(img_np, score, score_pred, title=f\"{'/'.join(file_path.split('/')[-2:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fn = os.path.join(os.path.dirname(model_fn), os.path.splitext(os.path.basename(file_path))[0]) + \".mp4\"\n",
    "\n",
    "export_widget_like_mp4(\n",
    "    images=img_np,                # (T,H,W,C) or (T,H,W)\n",
    "    scores=score,\n",
    "    scores_pred=score_pred,\n",
    "    out_mp4=out_fn,\n",
    "    fps=10.0,\n",
    "    title=file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_example():\n",
    "\n",
    "    file_path = df_frames.query('annotation_label == \"high_measurable\" or annotation_label == \"low_measurable\" or annotation_label == \"high_visible\" and tag != \"AC\"')['file_path'].drop_duplicates().sample(n=1).values[0]\n",
    "    \n",
    "    print(file_path)\n",
    "    idx = df.query(f'file_path == \"{file_path}\"').index[0] \n",
    "    X_d = test_ds[idx]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_d['img'].unsqueeze(0).permute(0, 2, 1, 3, 4).to(device))\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        levels = torch.tensor([0.0, 0.25, 0.5, 0.75, 1.0], device=probs.device)\n",
    "        score = (probs * levels).sum(dim=-1)  # [B, N]\n",
    "\n",
    "\n",
    "    visualize_sequence(X_d['img'].permute(1,2,3,0), X_d['scalar'], score.squeeze(0).cpu().numpy(), title=f\"{'/'.join(file_path.split('/')[-2:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33603298",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bins = torch.arange(1, 6, dtype=torch.float32) \n",
    "w_bins = w_bins / w_bins.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ce341",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([369458, 92519, 15579, 7674, 5970])\n",
    "w = 1.0 / c\n",
    "w = w / w.mean()\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38453fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = np.array([0.2,0.4,0.6,1.0,2.0])\n",
    "wb = wb / wb.mean()\n",
    "wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5757a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([0.0, 0.0, 0.25, 1.0, 0.75, 0.0, 0.0])\n",
    "s = torch.tensor([0.1, 0.2, 0.3, 0.9, 0.6, 0.2, 0.1])\n",
    "\n",
    "ds = s[1:] - s[:-1]\n",
    "dy = y[1:] - y[:-1]\n",
    "print(ds)\n",
    "print(dy)\n",
    "d = ds - dy \n",
    "print(d)\n",
    "print(np.abs(d).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(d).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9ba17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
