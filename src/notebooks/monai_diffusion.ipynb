{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1618d28b-1699-4cfb-9bec-b16c0b3c0517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-24 14:59:12,937 - Created a temporary directory at /tmp/tmpquag660o\n",
      "2023-04-24 14:59:12,939 - Writing /tmp/tmpquag660o/_remote_module_non_scriptable.py\n",
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.23.1\n",
      "Pytorch version: 1.12.1+cu113\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: /mnt/raid/home/jprieto/anaconda3/envs/torch_us/lib/python3.8/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: 2.12.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.13.1+cu113\n",
      "tqdm version: 4.64.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.4\n",
      "pandas version: 1.4.3\n",
      "einops version: 0.6.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: 0.4.3\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n",
      "You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms\n",
    "from monai.apps import MedNISTDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.utils import first, set_determinism\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generative.inferers import LatentDiffusionInferer\n",
    "from generative.losses.adversarial_loss import PatchAdversarialLoss\n",
    "from generative.losses.perceptual import PerceptualLoss\n",
    "from generative.networks.nets import AutoencoderKL, DiffusionModelUNet, PatchDiscriminator\n",
    "from generative.networks.schedulers import DDPMScheduler\n",
    "\n",
    "from generative.inferers import DiffusionInferer\n",
    "from generative.networks.nets import DiffusionModelUNet\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from loaders.ultrasound_dataset import USDataModule, USDataset\n",
    "from transforms.ultrasound_transforms import DiffusionEvalTransforms, DiffusionTrainTransforms\n",
    "\n",
    "from loaders.mr_dataset import MRDataModuleVolumes, MRDatasetVolumes\n",
    "from transforms.mr_transforms import MRDiffusionEvalTransforms, MRDiffusionTrainTransforms\n",
    "# from callbacks.logger import DiffusionImageLogger\n",
    "\n",
    "from nets import diffusion\n",
    "import pickle\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "mount_point = \"/mnt/raid/C1_ML_Analysis/\"\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51289899-b2fe-4b78-a914-bb7d32c8cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_test = \"/mnt/raid/C1_ML_Analysis/CSV_files/extract_frames_blind_sweeps_c1_30082022_wscores_1e-4_train_train_sample.parquet\"\n",
    "\n",
    "if(os.path.splitext(csv_test)[1] == \".csv\"):        \n",
    "    df_test = pd.read_csv(os.path.join(mount_point, csv_test))\n",
    "else:        \n",
    "    df_test = pd.read_parquet(os.path.join(mount_point, csv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db948b94-b738-4aa0-ad4e-b0bdcecfca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_transform = DiffusionTrainTransforms()\n",
    "valid_transform = DiffusionEvalTransforms()\n",
    "\n",
    "test_ds = USDataset(df_test, mount_point, img_column='img_path', transform=valid_transform, repeat_channel=False)\n",
    "test_data = DataLoader(test_ds, batch_size=1, num_workers=4, persistent_workers=True, pin_memory=True, shuffle=True, prefetch_factor=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3302e5-4060-4b3e-879b-21b2b672dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\")\n",
    "\n",
    "# model = DiffusionModelUNet(\n",
    "#     spatial_dims=2,\n",
    "#     in_channels=1,\n",
    "#     out_channels=1,\n",
    "#     num_channels=(128, 256, 256),\n",
    "#     attention_levels=(False, True, True),\n",
    "#     num_res_blocks=1,\n",
    "#     num_head_channels=256,\n",
    "# )\n",
    "# model.to(device)\n",
    "\n",
    "# scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=2.5e-5)\n",
    "\n",
    "# inferer = DiffusionInferer(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc05e1b-ce87-4829-afda-5c2e0208fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps = torch.randint(\n",
    "#     0, inferer.scheduler.num_train_timesteps, (2,)\n",
    "# ).long()\n",
    "# timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2497e-d5f7-4601-829c-8e233490ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# noise = torch.randn((1, 1, 64, 64))\n",
    "# noise = noise.to(device)\n",
    "# scheduler.set_timesteps(num_inference_steps=1000)\n",
    "# with autocast(enabled=True):\n",
    "#     image, intermediates = inferer.sample(\n",
    "#         input_noise=noise, diffusion_model=model, scheduler=scheduler, save_intermediates=True, intermediate_steps=100\n",
    "#     )\n",
    "\n",
    "# chain = torch.cat(intermediates, dim=-1)\n",
    "\n",
    "# plt.style.use(\"default\")\n",
    "# plt.imshow(chain[0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "# plt.tight_layout()\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420d7c04-49db-46c5-837c-01a3bfaa8f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackDataset(Dataset):\n",
    "    def __init__(self, dataset, multiple_slices=10):        \n",
    "        self.dataset = dataset\n",
    "        self.dataset.df = self.dataset.df.sample(frac=1).reset_index(drop=True)\n",
    "        self.multiple_slices = multiple_slices       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)//self.multiple_slices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        start_idx = idx*self.multiple_slices\n",
    "\n",
    "        return torch.stack([self.dataset[idx] for idx in range(start_idx, start_idx + self.multiple_slices)], dim=1)\n",
    "\n",
    "    \n",
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return tuple(d[i] for d in self.datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(d) for d in self.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662a16a1-ebfc-432f-8929-3062eaf61b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = USDataset(df_test, mount_point, img_column='img_path', transform=valid_transform, repeat_channel=False)\n",
    "test_ds_multiple_us = USDatasetMultipleSlices(test_ds, multiple_slices=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827a0bc3-b0d7-4926-bd52-6161b3c70969",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test = \"CSV_files/MR_diffusion_test.csv\"\n",
    "df_test_mr = pd.read_csv(os.path.join(mount_point, csv_test))\n",
    "test_ds_mr = MRDatasetVolumes(df_test_mr, mount_point=mount_point, img_column=\"img_path\", transform=MRDiffusionEvalTransforms(mount_point=mount_point, random_slice_size=10))\n",
    "\n",
    "concat_ds = ConcatDataset(test_ds_mr, test_ds_multiple_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44d28a7-d9b6-4a0a-8c9c-3a0bc762ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRUSDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, mr_dataset_train, us_dataset_train, mr_dataset_val, us_dataset_val, batch_size=4, num_workers=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mr_dataset_train = mr_dataset_train\n",
    "        self.us_dataset_train = us_dataset_train\n",
    "\n",
    "        self.mr_dataset_val = mr_dataset_val\n",
    "        self.us_dataset_val = us_dataset_val\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        self.train_ds = ConcatDataset(self.mr_dataset_train, self.us_dataset_train)\n",
    "        self.val_ds = ConcatDataset(self.mr_dataset_val, self.us_dataset_val)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, persistent_workers=True, pin_memory=True, shuffle=True, collate_fn=self.arrange_slices)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers, persistent_workers=True, pin_memory=True, collate_fn=self.arrange_slices)    \n",
    "\n",
    "    def arrange_slices(self, batch):\n",
    "        mr_batch = [mr for mr, us in batch]\n",
    "        us_batch = [us for mr, us in batch]        \n",
    "        mr_batch = torch.cat(mr_batch, axis=1).permute(dims=(1,0,2,3))\n",
    "        us_batch = torch.cat(us_batch, axis=1).permute(dims=(1,0,2,3))        \n",
    "        return mr_batch[torch.randperm(mr_batch.shape[0])], us_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765eeca5-e7c2-48b5-b340-eb2555a611a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n",
      "torch.Size([40, 1, 256, 256]) torch.Size([40, 1, 256, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m data_module\u001b[38;5;241m.\u001b[39msetup()\n\u001b[1;32m      3\u001b[0m loader \u001b[38;5;241m=\u001b[39m data_module\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m      6\u001b[0m     mr, us \u001b[38;5;241m=\u001b[39m l\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(mr\u001b[38;5;241m.\u001b[39mshape, us\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/mnt/raid/home/jprieto/anaconda3/envs/torch_us/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/mnt/raid/home/jprieto/anaconda3/envs/torch_us/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/raid/home/jprieto/anaconda3/envs/torch_us/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1315\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1315\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1317\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/mnt/raid/home/jprieto/anaconda3/envs/torch_us/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/raid/home/jprieto/anaconda3/envs/torch_us/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/mnt/raid/home/jprieto/anaconda3/envs/torch_us/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_module = MRUSDataModule(test_ds_mr, test_ds_multiple_us, test_ds_mr, test_ds_multiple_us)\n",
    "data_module.setup()\n",
    "loader = data_module.train_dataloader()\n",
    "\n",
    "for l in loader:\n",
    "    mr, us = l\n",
    "    print(mr.shape, us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650fdc12-b72c-45fd-9d31-03166e53ae74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
